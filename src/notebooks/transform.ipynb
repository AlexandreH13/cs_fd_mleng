{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/fraud_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class statistics:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def get_types(self):\n",
    "        return df.dtypes.value_counts()\n",
    "    \n",
    "    def get_label_statistics(self):\n",
    "        label_values = self.df['is_fraud'].value_counts().index.to_list()\n",
    "        print(f\"Label values encountered: {label_values}\")\n",
    "\n",
    "        not_str_vals = df['is_fraud'][~df['is_fraud'].isin(['0', '1']).values]\n",
    "        print(f\"Not string values: {not_str_vals}\")\n",
    "\n",
    "        print(f\"Not string values count: {not_str_vals.count()}\")\n",
    "\n",
    "    def consolidate(self):\n",
    "        print(\"#####Types#####\")\n",
    "        print(self.get_types())\n",
    "\n",
    "        print(\"#####Label#####\")\n",
    "        self.get_label_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####Types#####\n",
      "object     9\n",
      "float64    5\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "#####Label#####\n",
      "Label values encountered: ['0', '1', '1\"2020-12-24 16:56:24\"', '0\"2019-01-01 00:00:44\"']\n",
      "Not string values: 1781    1\"2020-12-24 16:56:24\"\n",
      "7780    0\"2019-01-01 00:00:44\"\n",
      "Name: is_fraud, dtype: object\n",
      "Not string values count: 2\n"
     ]
    }
   ],
   "source": [
    "stats = statistics(df)\n",
    "stats.consolidate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8124/173376496.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  random_samples = df_to_save.groupby('state').apply(lambda x: x.sample(2))\n"
     ]
    }
   ],
   "source": [
    "def get_test_sample(df):\n",
    "    \"\"\"Get a sample of the data for testing.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with the data to be sampled\n",
    "        state (str): State to be sampled\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the sampled data\n",
    "    \"\"\"\n",
    "    df_to_save = df\n",
    "\n",
    "    random_samples = df_to_save.groupby('state').apply(lambda x: x.sample(2))\n",
    "    indices_to_remove = random_samples.index.get_level_values(1)\n",
    "    df_to_save = df_to_save.drop(indices_to_remove)\n",
    "    df_to_save.to_csv(f'../data/processed/fraud_data_train.csv', index=False)\n",
    "    return random_samples\n",
    "test =  get_test_sample(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8124/2215822623.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  random_samples = df.groupby('state').apply(lambda x: x.sample(2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14420, 15)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples = df.groupby('state').apply(lambda x: x.sample(2))\n",
    "indices_to_remove = random_samples.index.get_level_values(1)\n",
    "df.drop(indices_to_remove).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prepare_data:\n",
    "    \"\"\"Class responsible for preparing the data for training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, state):\n",
    "        self.df = pd.read_csv('../data/raw/fraud_data.csv')\n",
    "        self.state = state\n",
    "\n",
    "    def job_encode(self)->pd.DataFrame:\n",
    "        \"\"\"Perform one hot encoding on the categorical columns\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Data Frame with new encoded columns\n",
    "        \"\"\"\n",
    "        df_res = self.get_state_df(self.df.copy())\n",
    "\n",
    "        encoder = LabelEncoder()\n",
    "        encoded_column = encoder.fit_transform(df_res['job'])\n",
    "\n",
    "        df_res['job'] = encoded_column\n",
    "\n",
    "        joblib.dump(encoder, f'../model/artifacts/encoder_{self.state}.pkl')\n",
    "        print(\"Encoder Salvo!\")\n",
    "\n",
    "\n",
    "        return df_res\n",
    "    \n",
    "    def convert_to_int(self, value):\n",
    "        \"\"\"Convert str values to int.\n",
    "\n",
    "        Args:\n",
    "            value (str, object): column value\n",
    "\n",
    "        Returns:\n",
    "            int: converted value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return int(value)  # Tentar converter para inteiro\n",
    "        except (ValueError, TypeError):\n",
    "            return None  # Substituir valores inv√°lidos por None\n",
    "        \n",
    "    def get_age_trans_time(self, year, bd):\n",
    "        return year - bd\n",
    "        \n",
    "    def get_age(self, df):\n",
    "        df['year_trans'] = df['trans_date_trans_time'].apply(lambda t: int(t[6:10]))\n",
    "        df['bt_year'] = df['dob'].apply(lambda bd: int(bd[-4:]))\n",
    "\n",
    "        df['age_trans_time'] = df.apply(lambda x: self.get_age_trans_time(x.year_trans, x.bt_year), axis=1)\n",
    "        df['dob'].apply(lambda bd: datetime.now().year - int(bd[-4:]))\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def age_cat(self, x):\n",
    "        if x < 18:\n",
    "            return '0-18'\n",
    "        elif x < 35:\n",
    "            return '18-35'\n",
    "        elif x < 60:\n",
    "            return '35-60'\n",
    "        else:\n",
    "            return '60+'\n",
    "        \n",
    "    def get_age_categorical(self, df):\n",
    "        df['age_cat'] = df.apply(lambda x: self.age_cat(x.age_trans_time), axis=1)\n",
    "    \n",
    "    def fix_data_types(self)->pd.DataFrame:\n",
    "        \"\"\"Fix the data type on the label column(is_fraud).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame ready for modeling.\n",
    "        \"\"\"\n",
    "        df_res = self.job_encode()\n",
    "        label = df_res['is_fraud']\n",
    "        print(f\"Invalid: {label[~label.isin(['0', '1'])].index}\")\n",
    "\n",
    "        df_res = df_res.iloc[label[label.isin(['0', '1'])].index] ## Keep only valid data\n",
    "        label = label.apply(self.convert_to_int)\n",
    "        df_res['is_fraud'] = label\n",
    "        return df_res\n",
    "    \n",
    "    def get_state_df(self, df):\n",
    "        \"\"\"Filter the DataFrame by state.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame to filter\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered DataFrame\n",
    "        \"\"\"\n",
    "        df_to_save = df\n",
    "        return df_to_save[df_to_save['state'] == self.state].reset_index(drop=True)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Execute all the steps to prepare the data. Save inside the processed folder.\n",
    "        \"\"\"\n",
    "        cols_ignore = ['trans_date_trans_time', 'merchant', 'category', 'city', 'trans_num', 'dob']\n",
    "        df_model = self.fix_data_types().sample(frac=1)\n",
    "        df_model = df_model.drop(columns=cols_ignore, axis=1)\n",
    "        df_model.to_csv(f'../data/processed/train_{self.state}.csv', index=False)\n",
    "\n",
    "    def simplified_version(self):\n",
    "        \"\"\"Save a simplified version of the DF\n",
    "           FOR TEST ONLY\n",
    "        \"\"\"\n",
    "        df_to_save = self.fix_data_types()\n",
    "        df_to_save = df_to_save[['amt', 'city_pop', 'lat', 'long', 'is_fraud', 'state']].sample(frac=1)\n",
    "        df_to_save[df_to_save['state'] == self.state].to_csv(f'../data/processed/train_{self.state}_simp.csv', index=False)\n",
    "\n",
    "    def get_json_format(self, df):\n",
    "        \"\"\"Convert from DataFrame to JSON format. \n",
    "           FOR TEST ONLY\n",
    "        \"\"\"\n",
    "\n",
    "        df_json = df.to_json(orient='records')\n",
    "        return df_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Salvo!\n",
      "Invalid: Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "prep = prepare_data(state='AK')\n",
    "prep.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"trans_date_trans_time\":\"23-03-2019 01:09\",\"merchant\":\"\\\\\"Greenholt, Jacobi and Gleason\\\\\"\",\"category\":\"gas_transport\",\"amt\":9.94,\"city\":\"Kaktovik\",\"state\":\"AK\",\"lat\":66.6933,\"long\":-153.994,\"city_pop\":239,\"job\":\"Careers information officer\",\"dob\":\"01-04-1996\",\"trans_num\":\"da81318af6e1918b067de24bbd9744d5\",\"merch_lat\":66.252098,\"merch_long\":-154.718147,\"is_fraud\":\"1\"},{\"trans_date_trans_time\":\"08-01-2019 22:49\",\"merchant\":\"Abshire PLC\",\"category\":\"entertainment\",\"amt\":17.85,\"city\":\"Wales\",\"state\":\"AK\",\"lat\":64.7556,\"long\":-165.6723,\"city_pop\":145,\"job\":\"\\\\\"Administrator, education\\\\\"\",\"dob\":\"09-11-1939\",\"trans_num\":\"5c9634262e76f3e5df1feff31d570c88\",\"merch_lat\":64.859572,\"merch_long\":-166.34388,\"is_fraud\":\"0\"}]'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['state'] == 'AK'].to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"trans_date_trans_time\":\"19-01-2019 16:14\",\"merchant\":\"Kerluke-Abshire\",\"category\":\"shopping_net\",\"amt\":52.41,\"city\":\"Glendale\",\"state\":\"CA\",\"lat\":34.1556,\"long\":-118.2322,\"city_pop\":172817,\"job\":\"Advertising account planner\",\"dob\":\"30-07-1982\",\"trans_num\":\"8856ef90738aa96672fef64982e487ce\",\"merch_lat\":34.60708,\"merch_long\":-118.297407,\"is_fraud\":\"0\"},{\"trans_date_trans_time\":\"03-07-2019 22:46\",\"merchant\":\"\\\\\"Schmeler, Bashirian and Price\\\\\"\",\"category\":\"shopping_net\",\"amt\":921.46,\"city\":\"Grenada\",\"state\":\"CA\",\"lat\":41.6125,\"long\":-122.5258,\"city_pop\":589,\"job\":\"Systems analyst\",\"dob\":\"21-12-1945\",\"trans_num\":\"1f9e8c49fffd6f4127ef70bb9229c574\",\"merch_lat\":40.704872,\"merch_long\":-122.724311,\"is_fraud\":\"1\"}]'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['state'] == 'CA'].to_json(orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs_fd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
